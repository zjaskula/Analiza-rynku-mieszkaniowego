import sysimport timeimport requestsfrom bs4 import BeautifulSoupheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',}city = sys.argv[1]posted_time = sys.argv[2] if len(sys.argv) > 2 and sys.argv[2] else ""daysSinceCreatedStr=""if posted_time != "":    daysSinceCreatedStr = f"&daysSinceCreated={posted_time}"domain = 'https://www.otodom.pl'city_url = f'https://www.otodom.pl/pl/wyniki/sprzedaz/mieszkanie/pomorskie/{city}/{city}/{city}?limit=72&ownerTypeSingleSelect=ALL{daysSinceCreatedStr}&buildYearMax=2025&by=LATEST&direction=DESC&page='data = []website = city_url + "1"html = requests.get(website, headers=headers).textsoup = BeautifulSoup(html, 'html.parser')text = soup.find("span", {"data-sentry-element": "StyledSpan"}).textnum_of_listings = int(text.split(" z ")[1]) // 72 + 1for i in range(1, num_of_listings + 1):    website = city_url + str(i)    html = requests.get(website, headers=headers).text    soup = BeautifulSoup(html, "html.parser")    links = soup.find_all("a", {"data-cy": "listing-item-link"})    data.extend(map(lambda x: domain + x.get('href'), links))    time.sleep(5)with open('data-links.txt', 'w+') as f:    for item in data:        f.write('%s\n' % item)